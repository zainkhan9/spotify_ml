{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Data Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intial EDA (Pre-Clustering Work)\n",
    "\n",
    "The datasets we are using are from a kaggle set that uses the Spotify API to query song data. https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"archive/data.csv\")\n",
    "df_artists = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "df_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "df_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "df_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995</td>\n",
       "      <td>['Carl Woitschach']</td>\n",
       "      <td>0.708</td>\n",
       "      <td>158648</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0</td>\n",
       "      <td>6KbQ3uYMLKb5jDxLF7wYDD</td>\n",
       "      <td>0.563</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-12.428</td>\n",
       "      <td>1</td>\n",
       "      <td>Singende Bataillone 1. Teil</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>118.469</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994</td>\n",
       "      <td>['Robert Schumann', 'Vladimir Horowitz']</td>\n",
       "      <td>0.379</td>\n",
       "      <td>282133</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>6KuQTIu1KoTTkLXKrwlLPV</td>\n",
       "      <td>0.901</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>-28.454</td>\n",
       "      <td>1</td>\n",
       "      <td>Fantasiestücke, Op. 111: Più tosto lento</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>83.972</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.604</td>\n",
       "      <td>['Seweryn Goszczyński']</td>\n",
       "      <td>0.749</td>\n",
       "      <td>104300</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0</td>\n",
       "      <td>6L63VW0PibdM1HDSBoqnoM</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-19.924</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 1.18 - Zamek kaniowski</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>107.177</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995</td>\n",
       "      <td>['Francisco Canaro']</td>\n",
       "      <td>0.781</td>\n",
       "      <td>180760</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0</td>\n",
       "      <td>6M94FkXd15sOAOQYRnWPN8</td>\n",
       "      <td>0.887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-14.734</td>\n",
       "      <td>0</td>\n",
       "      <td>Bebamos Juntos - Instrumental (Remasterizado)</td>\n",
       "      <td>0</td>\n",
       "      <td>1928-09-25</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>108.003</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.990</td>\n",
       "      <td>['Frédéric Chopin', 'Vladimir Horowitz']</td>\n",
       "      <td>0.210</td>\n",
       "      <td>687733</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0</td>\n",
       "      <td>6N6tiFZ9vLTSOIxkj8qKrd</td>\n",
       "      <td>0.908</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>-16.829</td>\n",
       "      <td>1</td>\n",
       "      <td>Polonaise-Fantaisie in A-Flat Major, Op. 61</td>\n",
       "      <td>1</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>62.149</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness                                   artists  danceability  \\\n",
       "0         0.995                       ['Carl Woitschach']         0.708   \n",
       "1         0.994  ['Robert Schumann', 'Vladimir Horowitz']         0.379   \n",
       "2         0.604                   ['Seweryn Goszczyński']         0.749   \n",
       "3         0.995                      ['Francisco Canaro']         0.781   \n",
       "4         0.990  ['Frédéric Chopin', 'Vladimir Horowitz']         0.210   \n",
       "\n",
       "   duration_ms  energy  explicit                      id  instrumentalness  \\\n",
       "0       158648  0.1950         0  6KbQ3uYMLKb5jDxLF7wYDD             0.563   \n",
       "1       282133  0.0135         0  6KuQTIu1KoTTkLXKrwlLPV             0.901   \n",
       "2       104300  0.2200         0  6L63VW0PibdM1HDSBoqnoM             0.000   \n",
       "3       180760  0.1300         0  6M94FkXd15sOAOQYRnWPN8             0.887   \n",
       "4       687733  0.2040         0  6N6tiFZ9vLTSOIxkj8qKrd             0.908   \n",
       "\n",
       "   key  liveness  loudness  mode  \\\n",
       "0   10    0.1510   -12.428     1   \n",
       "1    8    0.0763   -28.454     1   \n",
       "2    5    0.1190   -19.924     0   \n",
       "3    1    0.1110   -14.734     0   \n",
       "4   11    0.0980   -16.829     1   \n",
       "\n",
       "                                            name  popularity release_date  \\\n",
       "0                    Singende Bataillone 1. Teil           0         1928   \n",
       "1       Fantasiestücke, Op. 111: Più tosto lento           0         1928   \n",
       "2                 Chapter 1.18 - Zamek kaniowski           0         1928   \n",
       "3  Bebamos Juntos - Instrumental (Remasterizado)           0   1928-09-25   \n",
       "4    Polonaise-Fantaisie in A-Flat Major, Op. 61           1         1928   \n",
       "\n",
       "   speechiness    tempo  valence  year  \n",
       "0       0.0506  118.469   0.7790  1928  \n",
       "1       0.0462   83.972   0.0767  1928  \n",
       "2       0.9290  107.177   0.8800  1928  \n",
       "3       0.0926  108.003   0.7200  1928  \n",
       "4       0.0424   62.149   0.0693  1928  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the other datasets are aggregations of this one. The genre data is the only one that presents information that is not found in this dataset, and it provides aggregations of the data at the genre level or includes what genres an artist encapsualtes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popularity</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Cats\" 1981 Original London Cast</td>\n",
       "      <td>0.575083</td>\n",
       "      <td>0.442750</td>\n",
       "      <td>247260.000000</td>\n",
       "      <td>0.386336</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>0.287708</td>\n",
       "      <td>-14.205417</td>\n",
       "      <td>0.180675</td>\n",
       "      <td>115.983500</td>\n",
       "      <td>0.334433</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Cats\" 1983 Broadway Cast</td>\n",
       "      <td>0.862538</td>\n",
       "      <td>0.441731</td>\n",
       "      <td>287280.000000</td>\n",
       "      <td>0.406808</td>\n",
       "      <td>0.081158</td>\n",
       "      <td>0.315215</td>\n",
       "      <td>-10.690000</td>\n",
       "      <td>0.176212</td>\n",
       "      <td>103.044154</td>\n",
       "      <td>0.268865</td>\n",
       "      <td>33.076923</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Fiddler On The Roof” Motion Picture Chorus</td>\n",
       "      <td>0.856571</td>\n",
       "      <td>0.348286</td>\n",
       "      <td>328920.000000</td>\n",
       "      <td>0.286571</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.325786</td>\n",
       "      <td>-15.230714</td>\n",
       "      <td>0.118514</td>\n",
       "      <td>77.375857</td>\n",
       "      <td>0.354857</td>\n",
       "      <td>34.285714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Fiddler On The Roof” Motion Picture Orchestra</td>\n",
       "      <td>0.884926</td>\n",
       "      <td>0.425074</td>\n",
       "      <td>262890.962963</td>\n",
       "      <td>0.245770</td>\n",
       "      <td>0.073587</td>\n",
       "      <td>0.275481</td>\n",
       "      <td>-15.639370</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>88.667630</td>\n",
       "      <td>0.372030</td>\n",
       "      <td>34.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Joseph And The Amazing Technicolor Dreamcoat\"...</td>\n",
       "      <td>0.605444</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>232428.111111</td>\n",
       "      <td>0.429333</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.216111</td>\n",
       "      <td>-11.447222</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>120.329667</td>\n",
       "      <td>0.458667</td>\n",
       "      <td>42.555556</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             artists  acousticness  \\\n",
       "0                   \"Cats\" 1981 Original London Cast      0.575083   \n",
       "1                          \"Cats\" 1983 Broadway Cast      0.862538   \n",
       "2        \"Fiddler On The Roof” Motion Picture Chorus      0.856571   \n",
       "3     \"Fiddler On The Roof” Motion Picture Orchestra      0.884926   \n",
       "4  \"Joseph And The Amazing Technicolor Dreamcoat\"...      0.605444   \n",
       "\n",
       "   danceability    duration_ms    energy  instrumentalness  liveness  \\\n",
       "0      0.442750  247260.000000  0.386336          0.022717  0.287708   \n",
       "1      0.441731  287280.000000  0.406808          0.081158  0.315215   \n",
       "2      0.348286  328920.000000  0.286571          0.024593  0.325786   \n",
       "3      0.425074  262890.962963  0.245770          0.073587  0.275481   \n",
       "4      0.437333  232428.111111  0.429333          0.037534  0.216111   \n",
       "\n",
       "    loudness  speechiness       tempo   valence  popularity  key  mode  count  \n",
       "0 -14.205417     0.180675  115.983500  0.334433   38.000000    5     1     12  \n",
       "1 -10.690000     0.176212  103.044154  0.268865   33.076923    5     1     26  \n",
       "2 -15.230714     0.118514   77.375857  0.354857   34.285714    0     1      7  \n",
       "3 -15.639370     0.123200   88.667630  0.372030   34.444444    0     1     27  \n",
       "4 -11.447222     0.086000  120.329667  0.458667   42.555556   11     1      9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"year\").mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in this dataset mostly go over technical muscial information, more detail can be found at this link: https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/\n",
    "\n",
    "This link contains a detailed description of the popularity variable https://developer.spotify.com/documentation/web-api/reference/tracks/get-track/\n",
    "\n",
    "#### EDA\n",
    "\n",
    "Problem Statement Idea:\n",
    "\n",
    "- Can we extract genre from the various musical features at the song level, using an unsupervised learning technique?\n",
    "    - most likely learn genre via clustering, K-means or GMM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null value check, perhaps we aren't accounting for the way this data represents null values, i.e. empty brackets, zero values, certain text strings\n",
    "\n",
    "First off, how does spotify define genre? Let's take a look at how many genres they define genre in their aggregate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = df_genres[\"genres\"].unique()\n",
    "print(len(unique_genres))\n",
    "unique_genres[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_genres[df_w_genres[\"genres\"] == \"[]\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_genres[df_w_genres[\"genres\"] == \"[]\"].loc[56]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In trying to query our favorite artists from the song data, we noticed an interesting issue with how the artists are represented.\n",
    "\n",
    "There are 2,664 genres which is a very large amount, we see that there are multiple genres that have an \"acid\" prefix. Likely we will cluster and assign our own intuitive genres to each cluster or try to reduce this genre layer down to something we could use for supervised learning.\n",
    "\n",
    "We also see that there is an empty value for genre indicated by '[]', so we know that null values are indicated in this dataset beyond an 'na'\n",
    "\n",
    "Through this, we determined that the non-numeric variables are stored as strings (even though some appear to be lists, this comes from later EDA). This means we will have to do some preprocessing if we want to use pandas functions to query to through them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df[\"artists\"][0]))\n",
    "df[\"artists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"artists\"] = df[\"artists\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"artists\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_artist(artist):\n",
    "    return [True if df[\"artists\"][i] == [artist] else False for i in range(len(df[\"artists\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[query_artist(\"MGMT\")].sort_values(\"popularity\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist = top10_artists[\"artists\"]\n",
    "# artists_pop = top10_artists[\"popularity\"]\n",
    "# plt.bar(artist, artists_pop)\n",
    "top10_artists.plot.bar(\"artists\", \"popularity\")\n",
    "plt.xticks(rotation= 45)\n",
    "plt.title(\"Top 10 Most Popular Artists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to the popularity of artists in the dataset we see that the top 10 artists are relatively unknown artists (at least to us). Why could that be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the count value for these artists are extremely low, so likely these artists are \"one-hit wonders\" or have 2 very successful songs. Let's see how popularity measures for a universally loved artist like The Beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists[df_artists[\"artists\"] == \"The Beatles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, The Beatles have a popularity score of 48.06 compared to the above artists scores of 86-95. How does Spotify measure popularity? Let's look to the API\n",
    "\n",
    "The popularity of the track. The value will be between 0 and 100, with 100 being the most popular. The popularity of a track is a value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are.\n",
    "\n",
    "Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past. Duplicate tracks (e.g. the same track from a single and an album) are rated independently. Artist and album popularity is derived mathematically from track popularity. Note that the popularity value may lag actual popularity by a few days: the value is not updated in real time.\n",
    "\n",
    "So likely the Beatles score is averaged over all their songs, lowering their score as there is a count of 823. It is also interesting that popularity is affected by how recent a song has been played. Let's see how time affects popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_year['year'], df_year['popularity'])\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Popularity\")\n",
    "plt.title(\"Popularity Over Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we suspected popularity shows an increase over time, favoring more recent songs. This indicates that popularity is more better defined as \"current popularity\". Thus, the variable does not indicate how popular a song was when it came out, rather how popular a song was when the data was queried, roughly October, 11th 2020. This means it may not be a reliable variable to use, or we must use it acknowleding that it is not a measure of how popular an artist or song has been historically, rather currently.\n",
    "\n",
    "Let's look at the most popular songs in the dataset as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"popularity\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look a lot more like familiar artists. This indicates we want to stick to the song level data as opposed to data aggregated at the artist level so we do not lose detail about the data through issues like the \"one-hit wonder\" inflation seen above.\n",
    "\n",
    "It seems that we will want to focus our efforts on clustering the song level data using the technical music aspects to try and discern some innate pattern that we can abstract as genre. Let's look at some of this technical music data and observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"acousticness\"].hist()\n",
    "plt.title(\"Distribution of Acousticness\")\n",
    "plt.xlabel(\"Accousticness\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"danceability\"].hist()\n",
    "plt.title(\"Distribution of Danceability\")\n",
    "plt.xlabel(\"Danceability\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the spread for acousticness is heavily concentrated in the 0 and 1 bins, and Danceability is more evenly spread throughout with low concentration in the lower and upper bound bins\n",
    "\n",
    "We'll use the genre level data to look at trends in the technical music aspects, since it helps us learn how genre behavior trends for these technical music aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_genres[\"acousticness\"], df_genres[\"energy\"])\n",
    "plt.title(\"ScatterPlot of Genres of Acoustiness vs Energy\")\n",
    "plt.xlabel(\"Acousticness\")\n",
    "plt.ylabel(\"Energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_genres[\"acousticness\"], df_genres[\"loudness\"])\n",
    "plt.title(\"ScatterPlot of Genres of Acoustiness vs Loudness\")\n",
    "plt.xlabel(\"Acousticness\")\n",
    "plt.ylabel(\"Loudness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, through our EDA we've really decided on trying to cluster for genres at the song level. With multiple other aggregated data sets, we found that we lose specificity from the aggregation so we will choose the raw song data. Perhaps one way that we can measure our success is to compare our song clusters to the genres assigned to artists (though there is no genre variable in the song dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_cols = [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"valence\", \"speechiness\"]\n",
    "def plot_song(song):\n",
    "    song_df = df[df[\"name\"] == song]\n",
    "    song_df.iloc[0][plotting_cols].plot.bar()\n",
    "    plt.xticks(rotation= 45)\n",
    "    plt.title(\"Technical Values of \" + song)\n",
    "    plt.xlabel(\"Musical Features measured from 0-1\")\n",
    "    plt.ylabel(\"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_song(\"Ymca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Clustering Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"archive/data.csv\")\n",
    "df_artist = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "df_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "df_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "df_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing data down to the columns of interest for pca\n",
    "# I do not include explicit because that is not available in the genre aggregate data and I need the data to be consistent\n",
    "X = df[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'danceability', \n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo']]\n",
    "\n",
    "# Created this so I could see if there were better clusters with less data, the data staus consistently blob-like\n",
    "# X = df[['acousticness', \n",
    "#        'danceability',\n",
    "#        'energy',\n",
    "#        'danceability', \n",
    "#        'instrumentalness', \n",
    "#        'liveness', \n",
    "#        'loudness',\n",
    "#        'speechiness', \n",
    "#        'tempo']]\n",
    "\n",
    "#Performing PCA to see what's going on\n",
    "pca = PCA(n_components=2)\n",
    "#reducing data down to 2d and plotting it\n",
    "X_2d = pca.fit_transform(X)\n",
    "plt.scatter([i[0] for i in X_2d], [i[1] for i in X_2d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new PCA for visualizing explained variance for principle components\n",
    "pca2 = PCA()\n",
    "pca2.fit(X)\n",
    "    \n",
    "ks = range(1,12)\n",
    "ratios = pca2.explained_variance_ratio_\n",
    "#print(ratios)\n",
    "for k in ks:\n",
    "     #Sanity check to make sure the splicing is getting correct length\n",
    "    #print(len(ratios[:k]))\n",
    "    k_ratio = sum(ratios[:k])\n",
    "    print(f\"The fraction of the total variance explained by the first {k} principal component(s) is \" + str(k_ratio))\n",
    "\n",
    "summed_ratios = [sum(ratios[:i]) for i in range(len(ratios))]\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(len(ratios)), summed_ratios)\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Fraction of Total Variance\")\n",
    "plt.title(\"Fraction of total variance vs. number of principal components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to plot PCA\n",
    "def plot_pca():\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "         \n",
    "        plt.scatter([i[0] for i in X_2d], [i[1] for i in X_2d], c = 'b')\n",
    "\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        #plt.legend()\n",
    "        plt.title(\"Principal Components 1 and 2\")\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to plot kmeans and circles on top of the pca graph \n",
    "def plot_kmeans():\n",
    "    plt.plot(centers_2d[:,0], centers_2d[:,1], 'ro', label  = \"centroid\")\n",
    "\n",
    "    for ind,i in zip(kmeans.labels_,centers_2d):\n",
    "        #print(ind)\n",
    "        \n",
    "       \n",
    "        #print(np.where(kmeans.labels_==ind)[0])\n",
    "        class_inds=np.where(kmeans.labels_==ind)[0]\n",
    "        X_class = X_2d[class_inds]\n",
    "\n",
    "        dists = metrics.pairwise_distances([i], X_class)\n",
    "\n",
    "        max_dist=np.max(dists)\n",
    "        #print(max_dist)\n",
    "        plt.gca().add_artist(plt.Circle(i, max_dist, fill=False))\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this list of genres via https://examples.yourdictionary.com/major-types-of-music-from-around-the-world.html as \"Top Music Genres In the World\" : Classical, Country, Electronic dance music (EDM), Hip-hop ,Indie rock ,Jazz, K-pop, Metal, Oldies, Pop, Rap, Rhythm & blues (R&B), Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 12 because that's the number of top genres described above, excluding oldies since that isn't a spotify gebre\n",
    "kmeans = KMeans(n_clusters= 12)\n",
    "kmeans.fit(X)\n",
    "\n",
    "#reducing down the centers into 2d so they can be plotted along with our reduced data\n",
    "centers = kmeans.cluster_centers_\n",
    "centers_2d = pca.transform(centers)\n",
    "centers_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting with 2d clusters (when kmeans is trying to fit 2-d data instead of 11-d data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_2d = KMeans(n_clusters = 12)\n",
    "kmeans_2d.fit(X_2d)\n",
    "\n",
    "centers_2dreal = kmeans_2d.cluster_centers_\n",
    "centers_2dreal\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "         \n",
    "plt.scatter([i[0] for i in X_2d], [i[1] for i in X_2d], c = 'b')\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "        #plt.legend()\n",
    "plt.title(\"Principal Components 1 and 2\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.plot(centers_2dreal[:,0], centers_2dreal[:,1], 'ro', label  = \"centroid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters are more or less the same even when being done in 2d, this makes sense by the explained variance chart as we see that explained variance caps out at around 2 principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using 12 because that's the number of top genres described above, excluding oldies since that isn't a spotify gebre\n",
    "kmeans = KMeans(n_clusters= 12)\n",
    "kmeans.fit(X)\n",
    "\n",
    "#reducing down the centers into 2d so they can be plotted along with our reduced data\n",
    "centers = kmeans.cluster_centers_\n",
    "centers_2d = pca.transform(centers)\n",
    "centers_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure pca function works on its own\n",
    "plot_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the two functions together\n",
    "plot_pca()\n",
    "plot_kmeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_2d = KMeans(n_clusters= 12)\n",
    "kmeans_2d.fit(X_2d)\n",
    "centers = kmeans_2d.cluster_centers_\n",
    "#centers_2d\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "     \n",
    "plt.scatter([i[0] for i in X_2d], [i[1] for i in X_2d], c = 'b')\n",
    "\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "    #plt.legend()\n",
    "plt.title(\"Principal Components 1 and 2\")\n",
    "plt.tight_layout()\n",
    "        \n",
    "plt.plot(centers[:,0], centers[:,1], 'ro', label  = \"centroid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing our clusters in 2d space will be pretty tough if this is all correct. You can't really tell the difference between . I think this is mostly attributed to the fact that this data does not work well in a 2-dimensional space. If the data is doomed for dimension reduction then how do we visualize our clusters and try to discern genre?\n",
    "\n",
    "What if I up the number of clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 60)\n",
    "kmeans.fit(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "centers_2d = pca.transform(centers)\n",
    "\n",
    "plot_pca()\n",
    "plot_kmeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding clusters doesn't do much, still getting massive circles. Is my distance calculation correct? Also would be worth comparing circle functions to other people.\n",
    "\n",
    "#### Trying a different approach using the genre as a centroid\n",
    "First we cut down our genre data to our genres of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres[\"genres\"] = df_genres[\"genres\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))\n",
    "\n",
    "df_genres = df_genres[[True if (len(df_genres.loc[i, \"genres\"]) == 1) else False for i in range(len(df_genres))]]\n",
    "df_genres = df_genres.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_genres = [\"classical\", \"pop\", \"country\", \"edm\", \"hip hop\", \"indie rock\", \"jazz\", \"k-pop\", \"metal\", \"oldies\", \"rap\", \"r&b\", \"rock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_genre_df = df_genres[[True if df_genres.loc[i,\"genres\"][0] in popular_genres else False for i in range(len(df_genres))]]\n",
    "trimmed_genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_X = trimmed_genre_df[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'danceability', \n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo']]\n",
    "\n",
    "genre_y = trimmed_genre_df[\"genres\"]\n",
    "genre_2d = pca.transform(genre_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 12)\n",
    "kmeans.fit(X)\n",
    "centers = kmeans.cluster_centers_\n",
    "centers_2d = pca.transform(centers)\n",
    "plot_pca()\n",
    "plot_kmeans()\n",
    "plt.plot()\n",
    "plt.plot(genre_2d[:,0], genre_2d[:,1], 'yo', label  = \"Average Genre Value\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing where each of our cluster genres land to interpret associating clusters with genres later on \n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "         \n",
    "    plt.scatter([i[0] for i in X_2d], [i[1] for i in X_2d], c = 'black')\n",
    "\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    #plt.legend()\n",
    "    plt.title(\"Principal Components 1 and 2\")\n",
    "    plt.tight_layout()\n",
    "#plt.plot(genre_2d[:,0], genre_2d[:,1], 'yo', label  = \"Average Genre Value\")\n",
    "#plot_kmeans()\n",
    "plt.plot(centers_2d[:,0], centers_2d[:,1], 'ro', label  = \"centroid\")\n",
    "\n",
    "for i in range(len(genre_2d)):\n",
    "    center = genre_2d[i]\n",
    "    lab = genre_y.values[i][0]\n",
    "    plt.scatter(center[0], center[1], label = lab)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't visualize this very well in 2 dimensions, as these are values we can attribute to cluster centers and they are not clearly seperable. Additionally this data is at the song level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "genre_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'm trying to do is give a name to each cluster center by attributing it to the nearest euclidean distance of our genres we want to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating min distance and adding it into a list corresponding with the clusters\n",
    "center_genre_names = []\n",
    "for center in centers:\n",
    "    \n",
    "    min_dist = 1000000000\n",
    "    min_genre = \"\"\n",
    "    for i in range(len(genre_X)):\n",
    "        genre = genre_y.values[i]\n",
    "        row = genre_X.iloc[i]\n",
    "        dist = distance.euclidean(row.values, center)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_genre = genre\n",
    "    center_genre_names.append(min_genre)\n",
    "        \n",
    "\n",
    "center_genre_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing it out nicely\n",
    "for i in range(len(centers)):\n",
    "    print(\"Cluster \", str(i + 1), \"is closest to the genre:\", center_genre_names[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it looks like our clusters get most focused around these genres, meaning they aren't picking up on any underlying patterns in the data. It is also possible that these underlying patterns don't exist, perhaps we can learn more by looking at supervised clustering (Isaac's work)\n",
    "\n",
    "Seeing how things work if I turn the average values into cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 12)\n",
    "kmeans.fit(X)\n",
    "kmeans.cluster_centers_ = genre_X.values\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers == genre_X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_2d = pca.transform(centers)\n",
    "plot_pca()\n",
    "plot_kmeans()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Supervised\" Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "dat = pd.read_csv(\"archive/data.csv\")\n",
    "dat_artist = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "dat_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "dat_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "dat_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smaller Dataset work (\"Pure\", guarenteed songs in the genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix issue with genres list (From string to list of strings)\n",
    "dat_w_genres[\"genres\"] = dat_w_genres[\"genres\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will leave in empty list for one-genre, shouldn't be an issue\n",
    "# This leaves us with only artists that have worked in one genre\n",
    "dat_w_genres = dat_w_genres[[True if (len(dat_w_genres.loc[i, \"genres\"]) == 1) else False for i in range(len(dat_w_genres))]]\n",
    "dat_w_genres = dat_w_genres.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for the stringed list that we have for artists (same as for genres)\n",
    "dat[\"artists\"] = dat[\"artists\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all classical artists in \"Pure\" genres\n",
    "classical_artists = dat_w_genres[[True if \"classical\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]]\n",
    "\n",
    "# Get pop artists\n",
    "pop_artists = dat_w_genres[[True if \"pop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "pop_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classical artists\n",
    "classical_artists = classical_artists[\"artists\"]\n",
    "classical_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get country artists\n",
    "country_artists = dat_w_genres[[True if \"country\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "country_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get other genre artists\n",
    "edm_artists = dat_w_genres[[True if \"edm\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "hiphop_artists = dat_w_genres[[True if \"hip hop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "indierock_artists = dat_w_genres[[True if \"indie rock\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "jazz_artists = dat_w_genres[[True if \"jazz\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "kpop_artists = dat_w_genres[[True if \"k-pop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "metal_artists = dat_w_genres[[True if \"metal\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "# No oldies for spotify that I could find\n",
    "oldies_artists = dat_w_genres[[True if \"oldies\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "rap_artists = dat_w_genres[[True if \"rap\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "randb_artists = dat_w_genres[[True if \"r&b\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "rock_artists = dat_w_genres[[True if \"rock\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all songs from the pop, classical and country artists\n",
    "possible_pop = dat[[pop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_classical = dat[[classical_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_country = dat[[country_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all songs from the edm, hiphop and indierock artists\n",
    "possible_edm = dat[[edm_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_hiphop = dat[[hiphop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_indierock = dat[[indierock_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all songs from the jazz, kpop and metal artists\n",
    "possible_jazz = dat[[jazz_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_kpop = dat[[kpop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_metal = dat[[metal_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all songs from the rap, r and b and rock artists\n",
    "possible_rap = dat[[rap_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_randb = dat[[randb_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_rock = dat[[rock_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the numeric features, add the genre we choose\n",
    "pop = possible_pop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "pop[\"genre\"] = \"pop\"\n",
    "\n",
    "classical = possible_classical[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "classical[\"genre\"] = \"classical\"\n",
    "\n",
    "country = possible_country[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "country[\"genre\"] = \"country\"\n",
    "\n",
    "edm = possible_edm[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "edm[\"genre\"] = \"edm\"\n",
    "\n",
    "hiphop = possible_hiphop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "hiphop[\"genre\"] = \"hiphop\"\n",
    "\n",
    "indierock = possible_indierock[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "indierock[\"genre\"] = \"indierock\"\n",
    "\n",
    "jazz = possible_jazz[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "jazz[\"genre\"] = \"jazz\"\n",
    "\n",
    "kpop = possible_kpop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "kpop[\"genre\"] = \"kpop\"\n",
    "\n",
    "metal = possible_metal[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "metal[\"genre\"] = \"metal\"\n",
    "\n",
    "rap = possible_rap[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "rap[\"genre\"] = \"rap\"\n",
    "\n",
    "randb = possible_randb[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "randb[\"genre\"] = \"randb\"\n",
    "\n",
    "rock = possible_rock[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "rock[\"genre\"] = \"rock\"\n",
    "\n",
    "# Choose Genres\n",
    "allg = pd.concat([pop, rap, indierock, rock, metal, randb, kpop, jazz, classical, hiphop, edm, country])\n",
    "X = pd.concat([pop, rap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many of each genre\n",
    "allg[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA, find explained variance for each component\n",
    "pca = PCA(n_components=18)\n",
    "y = X[\"genre\"]\n",
    "X = X[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "pca.fit(X)\n",
    "pcavar = pca.explained_variance_ratio_\n",
    "plt.plot(pcavar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 2D Data visualization\n",
    "pca_mod = PCA(n_components=2)\n",
    "pcadat = pca_mod.fit_transform(X)\n",
    "d = pd.DataFrame(data=pcadat, columns=[\"Principal Component 1\", \"PC2\"])\n",
    "pops = d[(y == \"pop\").reset_index(drop = True)]\n",
    "raps = d[(y == \"rap\").reset_index(drop = True)]\n",
    "plt.plot(pops[\"Principal Component 1\"], pops[\"PC2\"], 'bo', raps[\"Principal Component 1\"], raps[\"PC2\"], 'ro')\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.legend((\"Pop\", \"Rap\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for best clustering of pop and rap (From project 3 function)\n",
    "train_labels = train_labels.reset_index(drop = True)\n",
    "test_labels = test_labels.reset_index(drop = True)\n",
    "\n",
    "### STUDENT START ###\n",
    "dat = pd.DataFrame(columns=[\"Type of Covariance\", \"Number of PCA Components\", \"Number of GMM Components\", \"Parameters\", \"Accuracy\"])\n",
    "l = 0\n",
    "    \n",
    "    # Start of Function\n",
    "    # Values of PCA Components\n",
    "for i in range(1, 18):\n",
    "        # Fit the PCA, get Pos and Neg\n",
    "    pca_mod = PCA(n_components=i)\n",
    "    pcadat=pca_mod.fit_transform(train_data) \n",
    "    data = pd.DataFrame(data=pcadat)\n",
    "        \n",
    "    pca_mod2 = PCA(n_components = i)\n",
    "    pcadat2 = pca_mod2.fit_transform(test_data) \n",
    "    data2 = pd.DataFrame(data=pcadat2)\n",
    "            \n",
    "    popsongs = data[train_labels == \"pop\"]\n",
    "    poplabels = train_labels[train_labels == \"pop\"]\n",
    "    \n",
    "\n",
    "    rapsongs = data[train_labels == \"rap\"]\n",
    "    raplabels = train_labels[train_labels == \"rap\"]\n",
    "    \n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        \n",
    "        params = 2 * (j + (j - 1) + (j*np.sum(range(1, i+1))))\n",
    "                \n",
    "        modelpop = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelrap = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "        poslik = modelpop.score_samples(data2)\n",
    "        neglik = modelrap.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Full\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "    \n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        params = 2 * ((2*j - 1) + i*j)\n",
    "            \n",
    "        modelpos = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelpos.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelneg = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelneg.fit(rapsongs, raplabels)\n",
    "            \n",
    "        poslik = modelpos.score_samples(data2)\n",
    "        neglik = modelneg.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Diag\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "    \n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        params = 2 * (3*j - 1)\n",
    "            \n",
    "        modelpos = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelpos.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelneg = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelneg.fit(rapsongs, raplabels)\n",
    "            \n",
    "        poslik = modelpos.score_samples(data2)\n",
    "        neglik = modelneg.score_samples(data2)\n",
    "            \n",
    "            # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "            # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Spherical\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "        \n",
    "    for j in range(1, 13):\n",
    "        params = 2 * (np.sum(range(1, i)) + 2*j - 1)\n",
    "                \n",
    "        modelpos = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelpos.fit(popsongs, poplabels)\n",
    "                \n",
    "        modelneg = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelneg.fit(rapsongs, raplabels)\n",
    "                \n",
    "        poslik = modelpos.score_samples(data2)\n",
    "        neglik = modelneg.score_samples(data2)\n",
    "                \n",
    "                # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Tied\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "\n",
    "        # Get model with best accuracy\n",
    "dat[dat[\"Accuracy\"] == max(dat[\"Accuracy\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Larger clustering work (\"Possible\" data - songs not guarenteed in genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimport data for fresh start\n",
    "dat = pd.read_csv(\"archive/data.csv\")\n",
    "dat_artist = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "dat_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "dat_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "dat_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists fix again\n",
    "dat[\"artists\"] = dat[\"artists\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all artists for a genre\n",
    "classical_artists = dat_w_genres[[True if \"classical\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "pop_artists = dat_w_genres[[True if \"pop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "country_artists = dat_w_genres[[True if \"country\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "edm_artists = dat_w_genres[[True if \"edm\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "hiphop_artists = dat_w_genres[[True if \"hip hop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "indierock_artists = dat_w_genres[[True if \"indie rock\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "jazz_artists = dat_w_genres[[True if \"jazz\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "kpop_artists = dat_w_genres[[True if \"k-pop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "metal_artists = dat_w_genres[[True if \"metal\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "# No oldies for spotify that I could find\n",
    "oldies_artists = dat_w_genres[[True if \"oldies\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "rap_artists = dat_w_genres[[True if \"rap\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "randb_artists = dat_w_genres[[True if \"r&b\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "rock_artists = dat_w_genres[[True if \"rock\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all songs from the artists in a genre\n",
    "possible_pop = dat[[pop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_classical = dat[[classical_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_country = dat[[country_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "\n",
    "possible_edm = dat[[edm_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_hiphop = dat[[hiphop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_indierock = dat[[indierock_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "\n",
    "possible_jazz = dat[[jazz_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_kpop = dat[[kpop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_metal = dat[[metal_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "\n",
    "possible_rap = dat[[rap_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_randb = dat[[randb_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_rock = dat[[rock_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose numeric features, add genre\n",
    "pop = possible_pop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "pop[\"genre\"] = \"pop\"\n",
    "\n",
    "classical = possible_classical[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "classical[\"genre\"] = \"classical\"\n",
    "\n",
    "country = possible_country[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "country[\"genre\"] = \"country\"\n",
    "\n",
    "edm = possible_edm[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "edm[\"genre\"] = \"edm\"\n",
    "\n",
    "hiphop = possible_hiphop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "hiphop[\"genre\"] = \"hiphop\"\n",
    "\n",
    "indierock = possible_indierock[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "indierock[\"genre\"] = \"indierock\"\n",
    "\n",
    "jazz = possible_jazz[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "jazz[\"genre\"] = \"jazz\"\n",
    "\n",
    "kpop = possible_kpop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "kpop[\"genre\"] = \"kpop\"\n",
    "\n",
    "metal = possible_metal[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "metal[\"genre\"] = \"metal\"\n",
    "\n",
    "rap = possible_rap[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "rap[\"genre\"] = \"rap\"\n",
    "\n",
    "randb = possible_randb[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "randb[\"genre\"] = \"randb\"\n",
    "\n",
    "rock = possible_rock[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "rock[\"genre\"] = \"rock\"\n",
    "\n",
    "# Choose Genres\n",
    "X = pd.concat([pop, rap, rock, indierock, metal, jazz, randb, kpop, classical, country, hiphop, edm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y properly\n",
    "y = X[\"genre\"]\n",
    "X = X[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of each\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just predicting rock gives us 28%\n",
    "# This was a sanity check -- modified multiple times\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to find best clustering model for all 12 genres\n",
    "train_labels = train_labels.reset_index(drop = True)\n",
    "test_labels = test_labels.reset_index(drop = True)\n",
    "\n",
    "### STUDENT START ###\n",
    "dat = pd.DataFrame(columns=[\"Type of Covariance\", \"Number of PCA Components\", \"Number of GMM Components\", \"Parameters\", \"Accuracy\"])\n",
    "l = 0\n",
    "    \n",
    "    # Start of Function\n",
    "    # Values of PCA Components\n",
    "for i in range(1, 18):\n",
    "        # Fit the PCA, get Pos and Neg\n",
    "    pca_mod = PCA(n_components=i)\n",
    "    pcadat=pca_mod.fit_transform(train_data) \n",
    "    data = pd.DataFrame(data=pcadat)\n",
    "        \n",
    "    pca_mod2 = PCA(n_components = i)\n",
    "    pcadat2 = pca_mod2.fit_transform(test_data) \n",
    "    data2 = pd.DataFrame(data=pcadat2)\n",
    "            \n",
    "    popsongs = data[train_labels == \"pop\"]\n",
    "    poplabels = train_labels[train_labels == \"pop\"]\n",
    "    \n",
    "    classicalsongs = data[train_labels == \"classical\"]\n",
    "    classicallabels = train_labels[train_labels == \"classical\"]\n",
    "    \n",
    "    hiphopsongs = data[train_labels == \"hiphop\"]\n",
    "    hiphoplabels = train_labels[train_labels == \"hiphop\"]\n",
    "    \n",
    "    jazzsongs = data[train_labels == \"jazz\"]\n",
    "    jazzlabels = train_labels[train_labels == \"jazz\"]\n",
    "    \n",
    "    indierocksongs = data[train_labels == \"indierock\"]\n",
    "    indierocklabels = train_labels[train_labels == \"indierock\"]\n",
    "    \n",
    "    rocksongs = data[train_labels == \"rock\"]\n",
    "    rocklabels = train_labels[train_labels == \"rock\"]\n",
    "    \n",
    "    edmsongs = data[train_labels == \"edm\"]\n",
    "    edmlabels = train_labels[train_labels == \"edm\"]\n",
    "    \n",
    "    countrysongs = data[train_labels == \"country\"]\n",
    "    countrylabels = train_labels[train_labels == \"country\"]\n",
    "    \n",
    "    kpopsongs = data[train_labels == \"kpop\"]\n",
    "    kpoplabels = train_labels[train_labels == \"kpop\"]\n",
    "    \n",
    "    metalsongs = data[train_labels == \"metal\"]\n",
    "    metallabels = train_labels[train_labels == \"metal\"]\n",
    "    \n",
    "    randbsongs = data[train_labels == \"randb\"]\n",
    "    randblabels = train_labels[train_labels == \"randb\"]\n",
    "\n",
    "    rapsongs = data[train_labels == \"rap\"]\n",
    "    raplabels = train_labels[train_labels == \"rap\"]\n",
    "    \n",
    "    for j in [1, 2, 3, 4]:\n",
    "        \n",
    "        params = 2 * (j + (j - 1) + (j*np.sum(range(1, i+1))))\n",
    "                \n",
    "        modelpop = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelhiphop = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelhiphop.fit(hiphopsongs, hiphoplabels)\n",
    "        \n",
    "        modeljazz = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modeljazz.fit(jazzsongs, jazzlabels)\n",
    "        \n",
    "        modelclassical = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelclassical.fit(classicalsongs, classicallabels)\n",
    "        \n",
    "        modeledm = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modeledm.fit(edmsongs, edmlabels)\n",
    "        \n",
    "        modelcountry = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelcountry.fit(countrysongs, countrylabels)\n",
    "        \n",
    "        modelrandb = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelrandb.fit(randbsongs, randblabels)\n",
    "        \n",
    "        modelindierock = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelindierock.fit(indierocksongs, indierocklabels)\n",
    "        \n",
    "        modelmetal = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelmetal.fit(metalsongs, metallabels)\n",
    "        \n",
    "        modelkpop = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelkpop.fit(kpopsongs, kpoplabels)\n",
    "        \n",
    "        modelrock = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelrock.fit(rocksongs, rocklabels)\n",
    "        \n",
    "        modelrap = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "        lik1 = modelpop.score_samples(data2)\n",
    "        lik2 = modelrap.score_samples(data2)\n",
    "        lik3 = modeledm.score_samples(data2)\n",
    "        lik4 = modelrock.score_samples(data2)\n",
    "        lik5 = modelindierock.score_samples(data2)\n",
    "        lik6 = modeljazz.score_samples(data2)\n",
    "        lik7 = modelcountry.score_samples(data2)\n",
    "        lik8 = modelclassical.score_samples(data2)\n",
    "        lik9 = modelkpop.score_samples(data2)\n",
    "        lik10 = modelmetal.score_samples(data2)\n",
    "        lik11 = modelrandb.score_samples(data2)\n",
    "        lik12 = modelhiphop.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            vals = [lik1[k], lik2[k], lik3[k], lik4[k], lik5[k], lik6[k], lik7[k], lik8[k], lik9[k], lik10[k], lik11[k], lik12[k]]\n",
    "            if np.argmax(vals) == 0:\n",
    "                labs.append(\"pop\")\n",
    "            elif np.argmax(vals) == 1:\n",
    "                labs.append(\"rap\")\n",
    "            elif np.argmax(vals) == 2:\n",
    "                labs.append(\"edm\")\n",
    "            elif np.argmax(vals) == 3:\n",
    "                labs.append(\"rock\")\n",
    "            elif np.argmax(vals) == 4:\n",
    "                labs.append(\"indierock\")\n",
    "            elif np.argmax(vals) == 5:\n",
    "                labs.append(\"jazz\")\n",
    "            elif np.argmax(vals) == 6:\n",
    "                labs.append(\"country\")\n",
    "            elif np.argmax(vals) == 7:\n",
    "                labs.append(\"classical\")\n",
    "            elif np.argmax(vals) == 8:\n",
    "                labs.append(\"kpop\")\n",
    "            elif np.argmax(vals) == 9:\n",
    "                labs.append(\"metal\")\n",
    "            elif np.argmax(vals) == 10:\n",
    "                labs.append(\"randb\")\n",
    "            else:\n",
    "                labs.append(\"hiphop\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Full\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "    \n",
    "    for j in [1, 2, 3, 4]:\n",
    "        params = 2 * ((2*j - 1) + i*j)\n",
    "            \n",
    "        modelpop = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelhiphop = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelhiphop.fit(hiphopsongs, hiphoplabels)\n",
    "        \n",
    "        modeljazz = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modeljazz.fit(jazzsongs, jazzlabels)\n",
    "        \n",
    "        modelclassical = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelclassical.fit(classicalsongs, classicallabels)\n",
    "        \n",
    "        modeledm = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modeledm.fit(edmsongs, edmlabels)\n",
    "        \n",
    "        modelcountry = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelcountry.fit(countrysongs, countrylabels)\n",
    "        \n",
    "        modelrandb = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelrandb.fit(randbsongs, randblabels)\n",
    "        \n",
    "        modelindierock = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelindierock.fit(indierocksongs, indierocklabels)\n",
    "        \n",
    "        modelmetal = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelmetal.fit(metalsongs, metallabels)\n",
    "        \n",
    "        modelkpop = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelkpop.fit(kpopsongs, kpoplabels)\n",
    "        \n",
    "        modelrock = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelrock.fit(rocksongs, rocklabels)\n",
    "        \n",
    "        modelrap = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "        lik1 = modelpop.score_samples(data2)\n",
    "        lik2 = modelrap.score_samples(data2)\n",
    "        lik3 = modeledm.score_samples(data2)\n",
    "        lik4 = modelrock.score_samples(data2)\n",
    "        lik5 = modelindierock.score_samples(data2)\n",
    "        lik6 = modeljazz.score_samples(data2)\n",
    "        lik7 = modelcountry.score_samples(data2)\n",
    "        lik8 = modelclassical.score_samples(data2)\n",
    "        lik9 = modelkpop.score_samples(data2)\n",
    "        lik10 = modelmetal.score_samples(data2)\n",
    "        lik11 = modelrandb.score_samples(data2)\n",
    "        lik12 = modelhiphop.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            vals = [lik1[k], lik2[k], lik3[k], lik4[k], lik5[k], lik6[k], lik7[k], lik8[k], lik9[k], lik10[k], lik11[k], lik12[k]]\n",
    "            if np.argmax(vals) == 0:\n",
    "                labs.append(\"pop\")\n",
    "            elif np.argmax(vals) == 1:\n",
    "                labs.append(\"rap\")\n",
    "            elif np.argmax(vals) == 2:\n",
    "                labs.append(\"edm\")\n",
    "            elif np.argmax(vals) == 3:\n",
    "                labs.append(\"rock\")\n",
    "            elif np.argmax(vals) == 4:\n",
    "                labs.append(\"indierock\")\n",
    "            elif np.argmax(vals) == 5:\n",
    "                labs.append(\"jazz\")\n",
    "            elif np.argmax(vals) == 6:\n",
    "                labs.append(\"country\")\n",
    "            elif np.argmax(vals) == 7:\n",
    "                labs.append(\"classical\")\n",
    "            elif np.argmax(vals) == 8:\n",
    "                labs.append(\"kpop\")\n",
    "            elif np.argmax(vals) == 9:\n",
    "                labs.append(\"metal\")\n",
    "            elif np.argmax(vals) == 10:\n",
    "                labs.append(\"randb\")\n",
    "            else:\n",
    "                labs.append(\"hiphop\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Diag\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "    \n",
    "    for j in [1, 2, 3, 4]:\n",
    "        params = 2 * (3*j - 1)\n",
    "            \n",
    "        modelpop = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelhiphop = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelhiphop.fit(hiphopsongs, hiphoplabels)\n",
    "        \n",
    "        modeljazz = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modeljazz.fit(jazzsongs, jazzlabels)\n",
    "        \n",
    "        modelclassical = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelclassical.fit(classicalsongs, classicallabels)\n",
    "        \n",
    "        modeledm = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modeledm.fit(edmsongs, edmlabels)\n",
    "        \n",
    "        modelcountry = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelcountry.fit(countrysongs, countrylabels)\n",
    "        \n",
    "        modelrandb = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelrandb.fit(randbsongs, randblabels)\n",
    "        \n",
    "        modelindierock = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelindierock.fit(indierocksongs, indierocklabels)\n",
    "        \n",
    "        modelmetal = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelmetal.fit(metalsongs, metallabels)\n",
    "        \n",
    "        modelkpop = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelkpop.fit(kpopsongs, kpoplabels)\n",
    "        \n",
    "        modelrock = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelrock.fit(rocksongs, rocklabels)\n",
    "        \n",
    "        modelrap = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "        lik1 = modelpop.score_samples(data2)\n",
    "        lik2 = modelrap.score_samples(data2)\n",
    "        lik3 = modeledm.score_samples(data2)\n",
    "        lik4 = modelrock.score_samples(data2)\n",
    "        lik5 = modelindierock.score_samples(data2)\n",
    "        lik6 = modeljazz.score_samples(data2)\n",
    "        lik7 = modelcountry.score_samples(data2)\n",
    "        lik8 = modelclassical.score_samples(data2)\n",
    "        lik9 = modelkpop.score_samples(data2)\n",
    "        lik10 = modelmetal.score_samples(data2)\n",
    "        lik11 = modelrandb.score_samples(data2)\n",
    "        lik12 = modelhiphop.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            vals = [lik1[k], lik2[k], lik3[k], lik4[k], lik5[k], lik6[k], lik7[k], lik8[k], lik9[k], lik10[k], lik11[k], lik12[k]]\n",
    "            if np.argmax(vals) == 0:\n",
    "                labs.append(\"pop\")\n",
    "            elif np.argmax(vals) == 1:\n",
    "                labs.append(\"rap\")\n",
    "            elif np.argmax(vals) == 2:\n",
    "                labs.append(\"edm\")\n",
    "            elif np.argmax(vals) == 3:\n",
    "                labs.append(\"rock\")\n",
    "            elif np.argmax(vals) == 4:\n",
    "                labs.append(\"indierock\")\n",
    "            elif np.argmax(vals) == 5:\n",
    "                labs.append(\"jazz\")\n",
    "            elif np.argmax(vals) == 6:\n",
    "                labs.append(\"country\")\n",
    "            elif np.argmax(vals) == 7:\n",
    "                labs.append(\"classical\")\n",
    "            elif np.argmax(vals) == 8:\n",
    "                labs.append(\"kpop\")\n",
    "            elif np.argmax(vals) == 9:\n",
    "                labs.append(\"metal\")\n",
    "            elif np.argmax(vals) == 10:\n",
    "                labs.append(\"randb\")\n",
    "            else:\n",
    "                labs.append(\"hiphop\")\n",
    "    \n",
    "            # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Spherical\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "        \n",
    "    for j in range(1, 7):\n",
    "        params = 2 * (np.sum(range(1, i)) + 2*j - 1)\n",
    "                \n",
    "        modelpop = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelpop.fit(popsongs, poplabels)\n",
    "                \n",
    "        modelhiphop = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelhiphop.fit(hiphopsongs, hiphoplabels)\n",
    "        \n",
    "        modeljazz = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modeljazz.fit(jazzsongs, jazzlabels)\n",
    "        \n",
    "        modelclassical = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelclassical.fit(classicalsongs, classicallabels)\n",
    "        \n",
    "        modeledm = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modeledm.fit(edmsongs, edmlabels)\n",
    "        \n",
    "        modelcountry = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelcountry.fit(countrysongs, countrylabels)\n",
    "        \n",
    "        modelrandb = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelrandb.fit(randbsongs, randblabels)\n",
    "        \n",
    "        modelindierock = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelindierock.fit(indierocksongs, indierocklabels)\n",
    "        \n",
    "        modelmetal = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelmetal.fit(metalsongs, metallabels)\n",
    "        \n",
    "        modelkpop = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelkpop.fit(kpopsongs, kpoplabels)\n",
    "        \n",
    "        modelrock = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelrock.fit(rocksongs, rocklabels)\n",
    "        \n",
    "        modelrap = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "        lik1 = modelpop.score_samples(data2)\n",
    "        lik2 = modelrap.score_samples(data2)\n",
    "        lik3 = modeledm.score_samples(data2)\n",
    "        lik4 = modelrock.score_samples(data2)\n",
    "        lik5 = modelindierock.score_samples(data2)\n",
    "        lik6 = modeljazz.score_samples(data2)\n",
    "        lik7 = modelcountry.score_samples(data2)\n",
    "        lik8 = modelclassical.score_samples(data2)\n",
    "        lik9 = modelkpop.score_samples(data2)\n",
    "        lik10 = modelmetal.score_samples(data2)\n",
    "        lik11 = modelrandb.score_samples(data2)\n",
    "        lik12 = modelhiphop.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            vals = [lik1[k], lik2[k], lik3[k], lik4[k], lik5[k], lik6[k], lik7[k], lik8[k], lik9[k], lik10[k], lik11[k], lik12[k]]\n",
    "            if np.argmax(vals) == 0:\n",
    "                labs.append(\"pop\")\n",
    "            elif np.argmax(vals) == 1:\n",
    "                labs.append(\"rap\")\n",
    "            elif np.argmax(vals) == 2:\n",
    "                labs.append(\"edm\")\n",
    "            elif np.argmax(vals) == 3:\n",
    "                labs.append(\"rock\")\n",
    "            elif np.argmax(vals) == 4:\n",
    "                labs.append(\"indierock\")\n",
    "            elif np.argmax(vals) == 5:\n",
    "                labs.append(\"jazz\")\n",
    "            elif np.argmax(vals) == 6:\n",
    "                labs.append(\"country\")\n",
    "            elif np.argmax(vals) == 7:\n",
    "                labs.append(\"classical\")\n",
    "            elif np.argmax(vals) == 8:\n",
    "                labs.append(\"kpop\")\n",
    "            elif np.argmax(vals) == 9:\n",
    "                labs.append(\"metal\")\n",
    "            elif np.argmax(vals) == 10:\n",
    "                labs.append(\"randb\")\n",
    "            else:\n",
    "                labs.append(\"hiphop\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Tied\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "\n",
    "        # Get maximum accuracy model\n",
    "dat[dat[\"Accuracy\"] == max(dat[\"Accuracy\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ready for 2 genre clustering on possible data set\n",
    "X = pd.concat([pop, rap])\n",
    "\n",
    "y = X[\"genre\"]\n",
    "X = X[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PCA to visualize\n",
    "pca_mod = PCA(n_components=2)\n",
    "pcadat = pca_mod.fit_transform(X)\n",
    "d = pd.DataFrame(data=pcadat, columns=[\"Principal Component 1\", \"PC2\"])\n",
    "pops = d[(y == \"pop\").reset_index(drop = True)]\n",
    "raps = d[(y == \"rap\").reset_index(drop = True)]\n",
    "plt.plot(pops[\"Principal Component 1\"], pops[\"PC2\"], 'bo', raps[\"Principal Component 1\"], raps[\"PC2\"], 'ro')\n",
    "plt.xticks([], [])\n",
    "plt.legend((\"Pop\", \"Rap\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for best clustering for Pop and Rap\n",
    "train_labels = train_labels.reset_index(drop = True)\n",
    "test_labels = test_labels.reset_index(drop = True)\n",
    "\n",
    "### STUDENT START ###\n",
    "dat = pd.DataFrame(columns=[\"Type of Covariance\", \"Number of PCA Components\", \"Number of GMM Components\", \"Parameters\", \"Accuracy\"])\n",
    "l = 0\n",
    "    \n",
    "    # Start of Function\n",
    "    # Values of PCA Components\n",
    "for i in range(1, 18):\n",
    "        # Fit the PCA, get Pos and Neg\n",
    "    pca_mod = PCA(n_components=i)\n",
    "    pcadat=pca_mod.fit_transform(train_data) \n",
    "    data = pd.DataFrame(data=pcadat)\n",
    "        \n",
    "    pca_mod2 = PCA(n_components = i)\n",
    "    pcadat2 = pca_mod2.fit_transform(test_data) \n",
    "    data2 = pd.DataFrame(data=pcadat2)\n",
    "            \n",
    "    popsongs = data[train_labels == \"pop\"]\n",
    "    poplabels = train_labels[train_labels == \"pop\"]\n",
    "    \n",
    "\n",
    "    rapsongs = data[train_labels == \"rap\"]\n",
    "    raplabels = train_labels[train_labels == \"rap\"]\n",
    "    \n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        \n",
    "        params = 2 * (j + (j - 1) + (j*np.sum(range(1, i+1))))\n",
    "                \n",
    "        modelpop = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelrap = GaussianMixture(n_components=j,covariance_type='full',random_state=12345)\n",
    "        modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "        poslik = modelpop.score_samples(data2)\n",
    "        neglik = modelrap.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Full\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "    \n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        params = 2 * ((2*j - 1) + i*j)\n",
    "            \n",
    "        modelpos = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelpos.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelneg = GaussianMixture(n_components=j,covariance_type='diag',random_state=12345)\n",
    "        modelneg.fit(rapsongs, raplabels)\n",
    "            \n",
    "        poslik = modelpos.score_samples(data2)\n",
    "        neglik = modelneg.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Diag\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "    \n",
    "    for j in [1, 2, 3, 4, 5, 6, 7, 8]:\n",
    "        params = 2 * (3*j - 1)\n",
    "            \n",
    "        modelpos = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelpos.fit(popsongs, poplabels)\n",
    "        \n",
    "        modelneg = GaussianMixture(n_components=j,covariance_type='spherical',random_state=12345)\n",
    "        modelneg.fit(rapsongs, raplabels)\n",
    "            \n",
    "        poslik = modelpos.score_samples(data2)\n",
    "        neglik = modelneg.score_samples(data2)\n",
    "            \n",
    "            # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "            # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Spherical\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "        \n",
    "    for j in range(1, 13):\n",
    "        params = 2 * (np.sum(range(1, i)) + 2*j - 1)\n",
    "                \n",
    "        modelpos = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelpos.fit(popsongs, poplabels)\n",
    "                \n",
    "        modelneg = GaussianMixture(n_components=j,covariance_type='tied',random_state=12345)\n",
    "        modelneg.fit(rapsongs, raplabels)\n",
    "                \n",
    "        poslik = modelpos.score_samples(data2)\n",
    "        neglik = modelneg.score_samples(data2)\n",
    "                \n",
    "                # Label More Likely outcome\n",
    "        labs = []\n",
    "        for k in range(len(poslik)):\n",
    "            if poslik[k] > neglik[k]:\n",
    "                labs.append(\"pop\")\n",
    "            else:\n",
    "                labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "        acc = []\n",
    "        for k in range(len(labs)):\n",
    "            if labs[k] == test_labels[k]:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "                    \n",
    "        totalacc = sum(acc) / len(acc)\n",
    "            \n",
    "        dat.loc[l] = [\"Tied\", i, j, params, totalacc]\n",
    "        l += 1\n",
    "\n",
    "        # Get max accuracy\n",
    "dat[dat[\"Accuracy\"] == max(dat[\"Accuracy\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add test on Pure songs (Uses the guarenteed genre songs as the test set)\n",
    "dat = pd.read_csv(\"archive/data.csv\")\n",
    "dat_artist = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "dat_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "dat_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "dat_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")\n",
    "\n",
    "# Genre list fix\n",
    "dat_w_genres[\"genres\"] = dat_w_genres[\"genres\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))\n",
    "\n",
    "# Will be left with some observations as [''], shouldn't matter given what we do later\n",
    "# Get list for pure artists\n",
    "dat_w_genres = dat_w_genres[[True if (len(dat_w_genres.loc[i, \"genres\"]) == 1) else False for i in range(len(dat_w_genres))]]\n",
    "dat_w_genres = dat_w_genres.reset_index(drop = True)\n",
    "\n",
    "# Artists list fix\n",
    "dat[\"artists\"] = dat[\"artists\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))\n",
    "\n",
    "# Get all pure pop, rap artists\n",
    "pop_artists = dat_w_genres[[True if \"pop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "rap_artists = dat_w_genres[[True if \"rap\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "\n",
    "# Find songs for those artists\n",
    "possible_pop = dat[[pop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_rap = dat[[rap_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "\n",
    "# Choose the correct features, add labels\n",
    "pops = possible_pop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "pops[\"genre\"] = \"pop\"\n",
    "\n",
    "raps = possible_rap[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "raps[\"genre\"] = \"rap\"\n",
    "\n",
    "Xs = pd.concat([pops, raps])\n",
    "\n",
    "y_labels = Xs[\"genre\"]\n",
    "y_labels = y_labels.reset_index(drop = True)\n",
    "x_data = Xs[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "x_data = x_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Possible model (2D fit on larger data set) on pure\n",
    "# Actually testing on best model\n",
    "train_labels = train_labels.reset_index(drop = True)\n",
    "\n",
    "pca_mod = PCA(n_components=7)\n",
    "pcadat=pca_mod.fit_transform(train_data) \n",
    "data = pd.DataFrame(data=pcadat)\n",
    "        \n",
    "pca_mod2 = PCA(n_components = 7)\n",
    "pcadat2 = pca_mod2.fit_transform(x_data) \n",
    "data2 = pd.DataFrame(data=pcadat2)\n",
    "\n",
    "popsongs = data[train_labels == \"pop\"]\n",
    "poplabels = train_labels[train_labels == \"pop\"]\n",
    "\n",
    "rapsongs = data[train_labels == \"rap\"]\n",
    "raplabels = train_labels[train_labels == \"rap\"]\n",
    "\n",
    "modelpop = GaussianMixture(n_components=6,covariance_type='tied',random_state=12345)\n",
    "modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "modelrap = GaussianMixture(n_components=6,covariance_type='tied',random_state=12345)\n",
    "modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "poslik = modelpop.score_samples(data2)\n",
    "neglik = modelrap.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "labs = []\n",
    "for k in range(len(poslik)):\n",
    "    if poslik[k] > neglik[k]:\n",
    "        labs.append(\"pop\")\n",
    "    else:\n",
    "        labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "acc = []\n",
    "for k in range(len(labs)):\n",
    "    if labs[k] == y_labels[k]:\n",
    "        acc.append(1)\n",
    "    else:\n",
    "        acc.append(0)\n",
    "                    \n",
    "totalacc = sum(acc) / len(acc)\n",
    "\n",
    "# Accuracy on Pure as test\n",
    "totalacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data is now the possible pop and rap songs (Not a perfect set since some songs may be neither, large data set)\n",
    "# Will use to test the pure models (built on guarenteed songs)\n",
    "test_data = pd.concat([pop, rap])\n",
    "test_labels = test_data[\"genre\"]\n",
    "test_labels = test_labels.reset_index(drop = True)\n",
    "test_data = test_data[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "test_data = test_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reimport to get the pure data\n",
    "dat = pd.read_csv(\"archive/data.csv\")\n",
    "dat_artist = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "dat_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "dat_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "dat_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for list of genres - changes from string of list to actual list\n",
    "dat_w_genres[\"genres\"] = dat_w_genres[\"genres\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))\n",
    "\n",
    "# Will be left with some observations as [''], shouldn't matter given what we do later\n",
    "dat_w_genres = dat_w_genres[[True if (len(dat_w_genres.loc[i, \"genres\"]) == 1) else False for i in range(len(dat_w_genres))]]\n",
    "dat_w_genres = dat_w_genres.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artist fix\n",
    "dat[\"artists\"] = dat[\"artists\"].apply(lambda x: x.replace(\"'\", \"\").strip('][').split(', '))\n",
    "# Find the artists\n",
    "pop_artists = dat_w_genres[[True if \"pop\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]\n",
    "rap_artists = dat_w_genres[[True if \"rap\" in dat_w_genres.loc[i,\"genres\"] else False for i in range(len(dat_w_genres))]][\"artists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the songs for pop and rap artists\n",
    "possible_pop = dat[[pop_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]\n",
    "possible_rap = dat[[rap_artists.isin(dat.loc[i, \"artists\"]).any() for i in range(len(dat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric features, add genres\n",
    "pop = possible_pop[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "pop[\"genre\"] = \"pop\"\n",
    "\n",
    "rap = possible_rap[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "rap[\"genre\"] = \"rap\"\n",
    "\n",
    "X = pd.concat([pop, rap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use previous best to evaluate other data set\n",
    "# Best model from pure using the possible data as a test set\n",
    "train_labels = X[\"genre\"]\n",
    "train_labels = train_labels.reset_index(drop = True)\n",
    "train_data = X[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "\n",
    "pca_mod = PCA(n_components=5)\n",
    "pcadat=pca_mod.fit_transform(train_data) \n",
    "data = pd.DataFrame(data=pcadat)\n",
    "        \n",
    "pca_mod2 = PCA(n_components = 5)\n",
    "pcadat2 = pca_mod2.fit_transform(test_data) \n",
    "data2 = pd.DataFrame(data=pcadat2)\n",
    "\n",
    "popsongs = data[train_labels == \"pop\"]\n",
    "poplabels = train_labels[train_labels == \"pop\"]\n",
    "\n",
    "rapsongs = data[train_labels == \"rap\"]\n",
    "raplabels = train_labels[train_labels == \"rap\"]\n",
    "\n",
    "modelpop = GaussianMixture(n_components=1,covariance_type='full',random_state=12345)\n",
    "modelpop.fit(popsongs, poplabels)\n",
    "        \n",
    "modelrap = GaussianMixture(n_components=1,covariance_type='full',random_state=12345)\n",
    "modelrap.fit(rapsongs, raplabels)\n",
    "            \n",
    "poslik = modelpop.score_samples(data2)\n",
    "neglik = modelrap.score_samples(data2)\n",
    "                \n",
    "                 # Label More Likely outcome\n",
    "labs = []\n",
    "for k in range(len(poslik)):\n",
    "    if poslik[k] > neglik[k]:\n",
    "        labs.append(\"pop\")\n",
    "    else:\n",
    "        labs.append(\"rap\")\n",
    "    \n",
    "                # Get accuracy\n",
    "acc = []\n",
    "for k in range(len(labs)):\n",
    "    if labs[k] == test_labels[k]:\n",
    "        acc.append(1)\n",
    "    else:\n",
    "        acc.append(0)\n",
    "                    \n",
    "totalacc = sum(acc) / len(acc)\n",
    "\n",
    "# Get the overall accuracy\n",
    "totalacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to Supervised (Predicting Popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"archive/data.csv\")\n",
    "dat_artist = pd.read_csv(\"archive/data_by_artist.csv\")\n",
    "dat_genres = pd.read_csv(\"archive/data_by_genres.csv\")\n",
    "dat_year = pd.read_csv(\"archive/data_by_year.csv\")\n",
    "dat_w_genres = pd.read_csv(\"archive/data_w_genres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features to the numeric ones, get Popularity as Y\n",
    "X = dat[['acousticness', \n",
    "       'danceability',\n",
    "       'energy',\n",
    "       'year', \n",
    "       'explicit',\n",
    "       'instrumentalness', \n",
    "       'key', \n",
    "       'liveness', \n",
    "       'loudness',\n",
    "       'mode', \n",
    "       'speechiness', \n",
    "       'tempo',\n",
    "        'valence', 'key', 'mode', 'loudness', 'explicit', 'duration_ms']]\n",
    "y = dat[\"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distplot to visualize the popularity values\n",
    "import seaborn as sns\n",
    "sns.distplot(y)\n",
    "plt.xlabel(\"Popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split on the intial data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look to see if non-distortionary scaling will impact our regression results\n",
    "from sklearn import preprocessing\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train_minmax = mm_scaler.fit_transform(X_train)\n",
    "X_test_minmax = mm_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Transformed linear regression, get Mean Squared Error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_minmax, y_train)\n",
    "preds = model.predict(X_test_minmax)\n",
    "\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classic linear regression no correction\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "preds = model1.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get score (R^2) value for the transformed linear regression\n",
    "model.score(X_test_minmax, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get score (R^2) value for the classic linear regression (slightly lower but functionally the same)\n",
    "model1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression normalizing the values\n",
    "model2 = LinearRegression(normalize=True)\n",
    "model2.fit(X_train, y_train)\n",
    "preds = model2.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See score, slight improvement overall\n",
    "model2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prediction vs Residual plot\n",
    "resid = preds - y_test\n",
    "plt.plot(preds, resid, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data frame for Pop, Pred, Resid\n",
    "data = {\"Actual Popularity\": y_test, \"Predicted\": preds, \"Residuals\": preds-y_test}\n",
    "data = pd.DataFrame(data=data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Prediction Plot\n",
    "import seaborn as sns\n",
    "g = sns.lmplot(x=\"Predicted\", y=\"Residuals\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice plot for popularity vs predicted\n",
    "import seaborn as sns\n",
    "g = sns.lmplot(x=\"Actual Popularity\", y=\"Predicted\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression CV\n",
    "reg = linear_model.RidgeCV(alphas=np.logspace(-9, 9, 19))\n",
    "reg.fit(X_train, y_train)\n",
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for Ridge CV Model\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO CV\n",
    "reg = linear_model.LassoCV(cv=5,alphas=np.logspace(-6, 6, 13), max_iter=1000000).fit(X_train, y_train)\n",
    "reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for LASSO\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV for Elastic Net\n",
    "regr = linear_model.ElasticNetCV(cv=5, random_state=0, alphas=np.logspace(-6,6,13), max_iter=10000000, l1_ratio=[.1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "regr.fit(X_train, y_train)\n",
    "regr.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get other parameter (l1 share)\n",
    "regr.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score for elastic net model\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean for later usage (binarize)\n",
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Logistic Regression for > 50\n",
    "y_train = [1 if i > 50 else 0 for i in y_train]\n",
    "y_test = [1 if i > 50 else 0 for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize on 50, find best model\n",
    "from sklearn.metrics import accuracy_score\n",
    "dat = pd.DataFrame(columns=[\"Regularization Parameter Lambda\", \"L1 or L2\", \"Accuracy\"])\n",
    "l = 0\n",
    "    # Get intitial vocabulary\n",
    "for i in np.logspace(-6,6,13):\n",
    "    modell1 = LogisticRegression(C=i, solver=\"liblinear\", multi_class=\"auto\", penalty=\"l1\", tol=0.015)\n",
    "    modell1.fit(X_train, y_train)\n",
    "    preds = modell1.predict(X_test)\n",
    "    dat.loc[l] = [(1/i), \"l1\", accuracy_score(y_test, preds)]\n",
    "    l+=1\n",
    "    \n",
    "    modell2 = LogisticRegression(C=i, solver=\"liblinear\", multi_class=\"auto\", penalty=\"l2\", tol=0.015)\n",
    "    modell2.fit(X_train, y_train)\n",
    "    preds = modell2.predict(X_test)\n",
    "    dat.loc[l] = [(1/i), \"l2\", accuracy_score(y_test, preds)]\n",
    "    l+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can predict if > 50 with 80% accuracy, best model\n",
    "dat[dat[\"Accuracy\"] == max(dat[\"Accuracy\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize on mean\n",
    "y_train = [1 if i > 31.56 else 0 for i in y_train]\n",
    "y_test = [1 if i > 31.56 else 0 for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best logistic regression for new binarize\n",
    "from sklearn.metrics import accuracy_score\n",
    "dat = pd.DataFrame(columns=[\"Regularization Parameter Lambda\", \"L1 or L2\", \"Accuracy\"])\n",
    "l = 0\n",
    "    # Get intitial vocabulary\n",
    "for i in np.logspace(-6,6,13):\n",
    "    modell1 = LogisticRegression(C=i, solver=\"liblinear\", multi_class=\"auto\", penalty=\"l1\", tol=0.015)\n",
    "    modell1.fit(X_train, y_train)\n",
    "    preds = modell1.predict(X_test)\n",
    "    dat.loc[l] = [(1/i), \"l1\", accuracy_score(y_test, preds)]\n",
    "    l+=1\n",
    "    \n",
    "    modell2 = LogisticRegression(C=i, solver=\"liblinear\", multi_class=\"auto\", penalty=\"l2\", tol=0.015)\n",
    "    modell2.fit(X_train, y_train)\n",
    "    preds = modell2.predict(X_test)\n",
    "    dat.loc[l] = [(1/i), \"l2\", accuracy_score(y_test, preds)]\n",
    "    l+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "dat[dat[\"Accuracy\"] == max(dat[\"Accuracy\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of 0's\n",
    "1 - (sum(y_train) / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get median for binarize\n",
    "np.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize on median\n",
    "y_train = [1 if i > 33 else 0 for i in y_train]\n",
    "y_test = [1 if i > 33 else 0 for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic with median binarize\n",
    "from sklearn.metrics import accuracy_score\n",
    "dat = pd.DataFrame(columns=[\"Regularization Parameter Lambda\", \"L1 or L2\", \"Accuracy\"])\n",
    "l = 0\n",
    "    # Get intitial vocabulary\n",
    "for i in np.logspace(-6,6,13):\n",
    "    modell1 = LogisticRegression(C=i, solver=\"liblinear\", multi_class=\"auto\", penalty=\"l1\", tol=0.015)\n",
    "    modell1.fit(X_train, y_train)\n",
    "    preds = modell1.predict(X_test)\n",
    "    dat.loc[l] = [(1/i), \"l1\", accuracy_score(y_test, preds)]\n",
    "    l+=1\n",
    "    \n",
    "    modell2 = LogisticRegression(C=i, solver=\"liblinear\", multi_class=\"auto\", penalty=\"l2\", tol=0.015)\n",
    "    modell2.fit(X_train, y_train)\n",
    "    preds = modell2.predict(X_test)\n",
    "    dat.loc[l] = [(1/i), \"l2\", accuracy_score(y_test, preds)]\n",
    "    l+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "dat[dat[\"Accuracy\"] == max(dat[\"Accuracy\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
